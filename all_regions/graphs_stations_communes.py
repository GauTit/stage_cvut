import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')

class TelecomAnalyzer:
    def __init__(self, csv_file_path):
        """
        Initialise l'analyseur avec le fichier CSV des sites tÃ©lÃ©com.
        
        Args:
            csv_file_path (str): Chemin vers le fichier CSV
        """
        self.csv_file_path = csv_file_path
        self.data = None
        self.common_stations = None
        self.exact_match = True  # Comparaison exacte des coordonnÃ©es
        
    def load_data(self):
        """
        Charge et nettoie les donnÃ©es du fichier CSV dÃ©limitÃ© par des points-virgules.
        """
        print("ğŸ“‚ Chargement des donnÃ©es (format point-virgule)...")
        
        try:
            # VÃ©rifier si le fichier existe
            import os
            if not os.path.exists(self.csv_file_path):
                print(f"âŒ Fichier non trouvÃ©: {self.csv_file_path}")
                return False
            
            print(f"ğŸ“„ Fichier trouvÃ©: {self.csv_file_path}")
            file_size = os.path.getsize(self.csv_file_path) / (1024*1024)
            print(f"ğŸ“ Taille: {file_size:.1f} MB")
            
            # Charger avec point-virgule comme sÃ©parateur
            print("ğŸ”„ Chargement avec dÃ©limiteur ';'...")
            
            # Essayer diffÃ©rents encodages pour les fichiers franÃ§ais
            encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings_to_try:
                try:
                    print(f"   Essai avec encoding: {encoding}")
                    self.data = pd.read_csv(
                        self.csv_file_path, 
                        sep=';',  # Point-virgule explicite
                        encoding=encoding,
                        low_memory=False,
                        on_bad_lines='skip'  # Ignorer les lignes malformÃ©es
                    )
                    
                    print(f"   âœ… ChargÃ© avec {encoding}: {len(self.data)} lignes")
                    break
                    
                except UnicodeDecodeError:
                    print(f"   âŒ Ã‰chec encoding {encoding}")
                    continue
                except Exception as e:
                    print(f"   âŒ Erreur avec {encoding}: {e}")
                    continue
            else:
                print("âŒ Tous les encodages ont Ã©chouÃ©")
                return False
            
            print(f"ğŸ“Š Lignes brutes chargÃ©es: {len(self.data):,}")
            
            # Nettoyer les noms de colonnes
            print("ğŸ§¹ Nettoyage des colonnes...")
            original_columns = list(self.data.columns)
            self.data.columns = [col.strip() for col in self.data.columns]
            
            print(f"ğŸ“‹ Colonnes disponibles: {list(self.data.columns)}")
            
            # VÃ©rifier les colonnes nÃ©cessaires
            required_columns = ['latitude', 'longitude', 'nom_op', 'nom_dep']
            available_columns = list(self.data.columns)
            
            print(f"ğŸ” VÃ©rification des colonnes requises:")
            missing_columns = []
            for col in required_columns:
                if col in available_columns:
                    print(f"   âœ… {col}: trouvÃ©e")
                else:
                    print(f"   âŒ {col}: MANQUANTE")
                    # Chercher des colonnes similaires
                    similar = [c for c in available_columns if col.lower() in c.lower() or c.lower() in col.lower()]
                    if similar:
                        print(f"      Colonnes similaires: {similar}")
                    missing_columns.append(col)
            
            if missing_columns:
                print(f"âŒ Colonnes manquantes critiques: {missing_columns}")
                print(f"ğŸ’¡ Colonnes disponibles dans le fichier:")
                for i, col in enumerate(available_columns, 1):
                    print(f"   {i:2d}. {col}")
                return False
            
            # Nettoyer les donnÃ©es Ã©tape par Ã©tape
            print(f"\nğŸ§¹ Nettoyage des donnÃ©es:")
            initial_count = len(self.data)
            print(f"   DÃ©part: {initial_count:,} lignes")
            
            # Supprimer les lignes vides dans les colonnes critiques
            for col in required_columns:
                before = len(self.data)
                # Supprimer les NaN et les chaÃ®nes vides
                self.data = self.data[
                    self.data[col].notna() & 
                    (self.data[col] != '') & 
                    (self.data[col] != ' ')
                ]
                after = len(self.data)
                if before != after:
                    print(f"   AprÃ¨s nettoyage '{col}': {after:,} lignes (-{before-after:,})")
            
            if len(self.data) == 0:
                print("âŒ Aucune ligne valide aprÃ¨s nettoyage des valeurs manquantes")
                return False
            
            # Convertir les coordonnÃ©es en numÃ©rique
            print("ğŸ”¢ Conversion des coordonnÃ©es GPS...")
            
            # Remplacer les virgules par des points si nÃ©cessaire (format franÃ§ais)
            if self.data['latitude'].dtype == 'object':
                self.data['latitude'] = self.data['latitude'].astype(str).str.replace(',', '.')
            if self.data['longitude'].dtype == 'object':
                self.data['longitude'] = self.data['longitude'].astype(str).str.replace(',', '.')
            
            self.data['latitude'] = pd.to_numeric(self.data['latitude'], errors='coerce')
            self.data['longitude'] = pd.to_numeric(self.data['longitude'], errors='coerce')
            
            # VÃ©rifier les conversions
            lat_invalid = self.data['latitude'].isna().sum()
            lon_invalid = self.data['longitude'].isna().sum()
            if lat_invalid > 0:
                print(f"   âš ï¸ {lat_invalid} latitudes invalides dÃ©tectÃ©es")
            if lon_invalid > 0:
                print(f"   âš ï¸ {lon_invalid} longitudes invalides dÃ©tectÃ©es")
            
            # Supprimer les coordonnÃ©es invalides
            before = len(self.data)
            self.data = self.data.dropna(subset=['latitude', 'longitude'])
            after = len(self.data)
            if before != after:
                print(f"   AprÃ¨s suppression coordonnÃ©es invalides: {after:,} lignes (-{before-after:,})")
            
            # Filtrer les coordonnÃ©es dans la plage de la France mÃ©tropolitaine
            before = len(self.data)
            france_filter = (
                (self.data['latitude'].between(41.0, 51.5)) &
                (self.data['longitude'].between(-5.5, 9.5))
            )
            self.data = self.data[france_filter]
            after = len(self.data)
            if before != after:
                print(f"   AprÃ¨s filtrage gÃ©ographique France: {after:,} lignes (-{before-after:,})")
            
            if len(self.data) == 0:
                print("âŒ Aucune donnÃ©e valide aprÃ¨s filtrage gÃ©ographique")
                return False
            
            # Statistiques finales
            print(f"\nâœ… DonnÃ©es chargÃ©es avec succÃ¨s:")
            print(f"   ğŸ“Š Sites totaux: {len(self.data):,}")
            print(f"   ğŸ¢ OpÃ©rateurs uniques: {self.data['nom_op'].nunique()}")
            print(f"   ğŸ—ºï¸ DÃ©partements uniques: {self.data['nom_dep'].nunique()}")
            
            # Afficher les opÃ©rateurs
            operators = self.data['nom_op'].unique()
            print(f"   ğŸ“¡ OpÃ©rateurs: {', '.join(operators)}")
            
            # Afficher quelques dÃ©partements
            departments = self.data['nom_dep'].unique()[:10]
            print(f"   ğŸ›ï¸ Premiers dÃ©partements: {', '.join(departments)}")
            
            # Ã‰chantillon des donnÃ©es
            print(f"\nğŸ“‹ Ã‰chantillon des donnÃ©es:")
            sample = self.data[['nom_op', 'nom_dep', 'latitude', 'longitude']].head(3)
            for idx, row in sample.iterrows():
                print(f"   {row['nom_op']} | {row['nom_dep']} | {row['latitude']:.5f}, {row['longitude']:.5f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur lors du chargement: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def find_common_stations(self):
        """
        Identifie les stations communes par comparaison EXACTE des coordonnÃ©es GPS.
        Une station commune = mÃªmes coordonnÃ©es latitude/longitude exactes.
        """
        print("ğŸ” Recherche des stations communes (coordonnÃ©es exactes)...")
        
        # CrÃ©er une clÃ© unique basÃ©e sur les coordonnÃ©es exactes
        self.data['coord_key'] = self.data['latitude'].astype(str) + '_' + self.data['longitude'].astype(str)
        
        print(f"ğŸ“Š CoordonnÃ©es uniques trouvÃ©es: {self.data['coord_key'].nunique():,}")
        
        # Grouper par coordonnÃ©es exactes
        location_groups = self.data.groupby('coord_key')
        
        common_stations_list = []
        multiple_sites_same_coords = 0
        multiple_operators_same_coords = 0
        
        for coord_key, group in location_groups:
            if len(group) > 1:  # Plusieurs sites aux mÃªmes coordonnÃ©es
                multiple_sites_same_coords += 1
                operators = group['nom_op'].unique()
                
                if len(operators) > 1:  # Plusieurs opÃ©rateurs diffÃ©rents
                    multiple_operators_same_coords += 1
                    
                    station_info = {
                        'coord_key': coord_key,
                        'latitude': group['latitude'].iloc[0],  # CoordonnÃ©es exactes
                        'longitude': group['longitude'].iloc[0],
                        'operators': list(operators),
                        'operator_count': len(operators),
                        'site_count': len(group),
                        'department': group['nom_dep'].iloc[0],
                        'region': group['nom_reg'].iloc[0] if 'nom_reg' in group.columns else 'N/A',
                        'commune': group['nom_com'].iloc[0] if 'nom_com' in group.columns else 'N/A',
                        'sites_details': group[['nom_op', 'num_site']].to_dict('records') if 'num_site' in group.columns else []
                    }
                    common_stations_list.append(station_info)
        
        self.common_stations = pd.DataFrame(common_stations_list)
        
        print(f"ğŸ“ RÃ©sultats de l'analyse:")
        print(f"   â€¢ {multiple_sites_same_coords:,} coordonnÃ©es avec plusieurs sites")
        print(f"   â€¢ {multiple_operators_same_coords:,} coordonnÃ©es avec plusieurs opÃ©rateurs")
        print(f"   â€¢ {len(self.common_stations):,} stations communes identifiÃ©es")
        
        if len(self.common_stations) > 0:
            # Statistiques sur le partage
            max_operators = self.common_stations['operator_count'].max()
            avg_operators = self.common_stations['operator_count'].mean()
            print(f"   â€¢ Maximum d'opÃ©rateurs sur une station: {max_operators}")
            print(f"   â€¢ Moyenne d'opÃ©rateurs par station commune: {avg_operators:.1f}")
        
        return self.common_stations
    
    def analyze_by_operator(self):
        """
        Analyse les statistiques par opÃ©rateur.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\nğŸ“ˆ Analyse par opÃ©rateur:")
        
        # Compter les occurrences de chaque opÃ©rateur dans les stations communes
        operator_counts = defaultdict(int)
        
        for _, station in self.common_stations.iterrows():
            for operator in station['operators']:
                operator_counts[operator] += 1
        
        operator_stats = pd.DataFrame(list(operator_counts.items()), 
                                    columns=['OpÃ©rateur', 'Stations_Communes'])
        operator_stats = operator_stats.sort_values('Stations_Communes', ascending=False)
        
        print(operator_stats.to_string(index=False))
        
        return operator_stats
    
    def analyze_by_department(self):
        """
        Analyse les statistiques par dÃ©partement.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\nğŸ—ºï¸ Analyse par dÃ©partement:")
        
        dept_stats = self.common_stations['department'].value_counts().head(15)
        dept_df = pd.DataFrame({
            'DÃ©partement': dept_stats.index,
            'Stations_Communes': dept_stats.values,
            'Pourcentage': (dept_stats.values / len(self.common_stations) * 100).round(1)
        })
        
        print(dept_df.to_string(index=False))
        
        return dept_df
    
    def create_operator_sharing_matrix(self):
        """
        CrÃ©e une matrice montrant combien de stations communes chaque paire d'opÃ©rateurs partage.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("âŒ Aucune station commune pour crÃ©er la matrice")
            return None
        
        print("ğŸ“Š CrÃ©ation de la matrice de partage entre opÃ©rateurs...")
        
        # Obtenir tous les opÃ©rateurs uniques
        all_operators = sorted(list(set([op for station in self.common_stations['operators'] for op in station])))
        
        print(f"   OpÃ©rateurs dÃ©tectÃ©s: {all_operators}")
        
        # CrÃ©er une matrice vide
        matrix = pd.DataFrame(0, index=all_operators, columns=all_operators)
        
        # Remplir la matrice
        for _, station in self.common_stations.iterrows():
            operators = station['operators']
            # Pour chaque paire d'opÃ©rateurs dans cette station
            for i, op1 in enumerate(operators):
                for j, op2 in enumerate(operators):
                    if i != j:  # Ã‰viter de compter un opÃ©rateur avec lui-mÃªme
                        matrix.loc[op1, op2] += 1
        
        # La matrice est symÃ©trique, donc diviser par 2 pour Ã©viter le double comptage
        # Mais garder la diagonale Ã  0
        for i in range(len(all_operators)):
            for j in range(i+1, len(all_operators)):
                op1, op2 = all_operators[i], all_operators[j]
                shared_count = matrix.loc[op1, op2]
                matrix.loc[op1, op2] = shared_count
                matrix.loc[op2, op1] = shared_count
        
        print(f"âœ… Matrice de partage crÃ©Ã©e ({len(all_operators)}x{len(all_operators)})")
        
        # Afficher la matrice
        print(f"\nğŸ“‹ MATRICE DE PARTAGE ENTRE OPÃ‰RATEURS:")
        print(f"   (Nombre de stations communes par paire d'opÃ©rateurs)")
        print(matrix)
        
        # Statistiques intÃ©ressantes
        print(f"\nğŸ¯ STATISTIQUES DE PARTAGE:")
        
        # Paires les plus partagÃ©es
        upper_triangle = matrix.where(np.triu(np.ones(matrix.shape), k=1).astype(bool))
        max_sharing = upper_triangle.max().max()
        
        if max_sharing > 0:
            max_pairs = []
            for col in upper_triangle.columns:
                for idx in upper_triangle.index:
                    if upper_triangle.loc[idx, col] == max_sharing:
                        max_pairs.append((idx, col, max_sharing))
            
            print(f"   ğŸ† Paire(s) avec le plus de partage ({max_sharing} stations):")
            for op1, op2, count in max_pairs:
                print(f"      â€¢ {op1} â†” {op2}: {count} stations communes")
        
        # Total de partages par opÃ©rateur
        sharing_totals = matrix.sum(axis=1) / 2  # Diviser par 2 car matrice symÃ©trique
        sharing_totals = sharing_totals.sort_values(ascending=False)
        
        print(f"\n   ğŸ“Š Total de partages par opÃ©rateur:")
        for op, total in sharing_totals.items():
            print(f"      â€¢ {op}: {int(total)} partages")
        
        return matrix
    
    def visualize_sharing_matrix(self, matrix=None):
        """
        CrÃ©e une heatmap de la matrice de partage.
        """
        if matrix is None:
            matrix = self.create_operator_sharing_matrix()
        
        if matrix is None:
            return
        
        try:
            # Essayer avec seaborn (plus joli)
            plt.figure(figsize=(10, 8))
            
            sns.heatmap(matrix, 
                       annot=True,  # Afficher les valeurs
                       fmt='d',     # Format entier
                       cmap='Blues', 
                       square=True,
                       cbar_kws={'label': 'Nombre de stations communes'},
                       linewidths=0.5)
            
            plt.title('Matrice de Partage entre OpÃ©rateurs\n(Nombre de stations communes)', 
                     fontsize=14, fontweight='bold', pad=20)
            plt.xlabel('OpÃ©rateurs', fontweight='bold')
            plt.ylabel('OpÃ©rateurs', fontweight='bold')
            
            # Rotation des labels pour une meilleure lisibilitÃ©
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            
            plt.tight_layout()
            plt.show()
            
        except ImportError:
            print("âš ï¸ Seaborn non disponible, crÃ©ation d'une heatmap simple...")
            self._create_simple_matrix_plot(matrix)
        except Exception as e:
            print(f"âš ï¸ Erreur avec seaborn: {e}")
            self._create_simple_matrix_plot(matrix)
    
    def _create_simple_matrix_plot(self, matrix):
        """
        CrÃ©e une heatmap simple avec matplotlib seulement.
        """
        plt.figure(figsize=(10, 8))
        
        # CrÃ©er la heatmap avec matplotlib
        im = plt.imshow(matrix.values, cmap='Blues', aspect='auto')
        
        # Ajouter les valeurs sur chaque case
        for i in range(len(matrix.index)):
            for j in range(len(matrix.columns)):
                plt.text(j, i, int(matrix.iloc[i, j]), 
                        ha='center', va='center', fontweight='bold')
        
        # Configuration des axes
        plt.xticks(range(len(matrix.columns)), matrix.columns, rotation=45, ha='right')
        plt.yticks(range(len(matrix.index)), matrix.index)
        
        plt.title('Matrice de Partage entre OpÃ©rateurs\n(Nombre de stations communes)', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('OpÃ©rateurs', fontweight='bold')
        plt.ylabel('OpÃ©rateurs', fontweight='bold')
        
        # Ajouter une barre de couleur
        cbar = plt.colorbar(im)
        cbar.set_label('Nombre de stations communes', rotation=270, labelpad=20)
        
        plt.tight_layout()
        plt.show()
    
    def print_matrix_table(self, matrix=None):
        """
        Affiche la matrice sous forme de tableau bien formatÃ© dans la console.
        """
        if matrix is None:
            matrix = self.create_operator_sharing_matrix()
        
        if matrix is None:
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š MATRICE DE PARTAGE ENTRE OPÃ‰RATEURS")
        print("="*80)
        print("(Nombre de stations communes par paire d'opÃ©rateurs)")
        print()
        
        # Formatter pour un affichage propre
        operators = list(matrix.columns)
        
        # En-tÃªte
        header = "           "
        for op in operators:
            header += f"{op:>8s} "
        print(header)
        print("-" * len(header))
        
        # Lignes de donnÃ©es
        for i, op1 in enumerate(operators):
            row = f"{op1:>10s} "
            for j, op2 in enumerate(operators):
                value = int(matrix.loc[op1, op2])
                if i == j:  # Diagonale
                    row += f"{'':>8s} "
                else:
                    row += f"{value:>8d} "
            print(row)
        
        print("\nğŸ’¡ Lecture: La case (Ligne, Colonne) indique combien de stations")
        print("   les deux opÃ©rateurs partagent ensemble.")
        print("="*80)
    
    def analyze_operator_pairs(self):
        """
        Analyse dÃ©taillÃ©e des paires d'opÃ©rateurs qui partagent le plus.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("âŒ Aucune donnÃ©e pour l'analyse des paires")
            return None
        
        print("ğŸ” Analyse dÃ©taillÃ©e des paires d'opÃ©rateurs...")
        
        # Compter les occurrences de chaque paire
        pair_counts = {}
        pair_stations = {}  # Pour stocker les dÃ©tails des stations
        
        for idx, station in self.common_stations.iterrows():
            operators = sorted(station['operators'])  # Tri pour cohÃ©rence
            station_info = {
                'commune': station['commune'],
                'department': station['department'],
                'latitude': station['latitude'],
                'longitude': station['longitude']
            }
            
            # GÃ©nÃ©rer toutes les paires possibles
            from itertools import combinations
            for pair in combinations(operators, 2):
                pair_key = f"{pair[0]} + {pair[1]}"
                
                if pair_key not in pair_counts:
                    pair_counts[pair_key] = 0
                    pair_stations[pair_key] = []
                
                pair_counts[pair_key] += 1
                pair_stations[pair_key].append(station_info)
        
        # Convertir en DataFrame et trier
        pairs_df = pd.DataFrame(list(pair_counts.items()), 
                               columns=['Paire_OpÃ©rateurs', 'Stations_Communes'])
        pairs_df = pairs_df.sort_values('Stations_Communes', ascending=False)
        
        print(f"\nğŸ“Š TOP 10 DES PAIRES D'OPÃ‰RATEURS:")
        for idx, row in pairs_df.head(10).iterrows():
            pair_name = row['Paire_OpÃ©rateurs']
            count = row['Stations_Communes']
            print(f"   {idx+1:2d}. {pair_name}: {count} stations communes")
            
            # Afficher quelques exemples de stations
            if count <= 3:  # Si peu de stations, afficher toutes
                stations = pair_stations[pair_name]
                for station in stations:
                    print(f"       ğŸ“ {station['commune']} ({station['department']})")
            else:  # Sinon, afficher les 3 premiÃ¨res
                stations = pair_stations[pair_name][:3]
                for station in stations:
                    print(f"       ğŸ“ {station['commune']} ({station['department']})")
                if count > 3:
                    print(f"       ... et {count-3} autres stations")
            print()
        
        return pairs_df, pair_stations
        """
        Analyse alternative utilisant la colonne id_site_partage si disponible.
        """
        if 'id_site_partage' not in self.data.columns:
            print("âŒ Colonne 'id_site_partage' non disponible")
            return None
        
        print("ğŸ” Analyse par id_site_partage...")
        
        # Filtrer les sites avec un ID de partage
        shared_sites = self.data[self.data['id_site_partage'].notna() & (self.data['id_site_partage'] != '')]
        
        if len(shared_sites) == 0:
            print("âŒ Aucun site avec id_site_partage renseignÃ©")
            return None
        
        print(f"ğŸ“Š {len(shared_sites)} sites avec id_site_partage")
        
        # Grouper par ID de partage
        sharing_groups = shared_sites.groupby('id_site_partage')
        
        shared_infrastructure = []
        
        for share_id, group in sharing_groups:
            if len(group) > 1:
                operators = group['nom_op'].unique()
                if len(operators) > 1:
                    shared_info = {
                        'share_id': share_id,
                        'operators': list(operators),
                        'operator_count': len(operators),
                        'site_count': len(group),
                        'departments': list(group['nom_dep'].unique()),
                        'coordinates': list(group[['latitude', 'longitude']].drop_duplicates().values)
                    }
                    shared_infrastructure.append(shared_info)
        
        print(f"ğŸ¯ {len(shared_infrastructure)} infrastructures partagÃ©es via id_site_partage")
        
        return pd.DataFrame(shared_infrastructure)
    def get_top_shared_stations(self, n=20):
        """
        Retourne les stations avec le plus d'opÃ©rateurs.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("âŒ Aucune station commune Ã  afficher")
            return pd.DataFrame()
        
        top_stations = self.common_stations.nlargest(n, 'operator_count')[
            ['commune', 'department', 'operator_count', 'operators', 'latitude', 'longitude', 'site_count']
        ]
        
        print(f"\nğŸ† Top {min(n, len(top_stations))} des stations avec le plus d'opÃ©rateurs (coordonnÃ©es exactes):")
        for idx, station in top_stations.iterrows():
            operators_str = ', '.join(station['operators'])
            print(f"   ğŸ“ {station['commune']} ({station['department']})")
            print(f"      ğŸ¢ {station['operator_count']} opÃ©rateurs: {operators_str}")
            print(f"      ğŸ“Š {station['site_count']} sites | ğŸ—ºï¸ {station['latitude']:.6f}, {station['longitude']:.6f}")
            print()
        
        return top_stations
    
    def create_visualizations(self):
        """
        CrÃ©e les graphiques d'analyse.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        # Configuration des graphiques
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ğŸ“Š Analyse des Stations TÃ©lÃ©com Communes', fontsize=16, fontweight='bold')
        
        # 1. Stations communes par opÃ©rateur
        operator_stats = self.analyze_by_operator()
        axes[0, 0].bar(operator_stats['OpÃ©rateur'], operator_stats['Stations_Communes'], 
                       color='skyblue', edgecolor='navy')
        axes[0, 0].set_title('Stations communes par opÃ©rateur')
        axes[0, 0].set_xlabel('OpÃ©rateur')
        axes[0, 0].set_ylabel('Nombre de stations communes')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. Top 10 dÃ©partements
        dept_stats = self.analyze_by_department().head(10)
        axes[0, 1].barh(dept_stats['DÃ©partement'], dept_stats['Stations_Communes'], 
                        color='lightcoral')
        axes[0, 1].set_title('Top 10 dÃ©partements - Stations communes')
        axes[0, 1].set_xlabel('Nombre de stations communes')
        
        # 3. Distribution du nombre d'opÃ©rateurs par station
        operator_count_dist = self.common_stations['operator_count'].value_counts().sort_index()
        axes[1, 0].bar(operator_count_dist.index, operator_count_dist.values, 
                       color='lightgreen', edgecolor='darkgreen')
        axes[1, 0].set_title('Distribution: Nombre d\'opÃ©rateurs par station')
        axes[1, 0].set_xlabel('Nombre d\'opÃ©rateurs')
        axes[1, 0].set_ylabel('Nombre de stations')
        
        # 4. RÃ©partition gÃ©ographique (sample)
        sample_stations = self.common_stations.sample(min(1000, len(self.common_stations)))
        scatter = axes[1, 1].scatter(sample_stations['longitude'], sample_stations['latitude'], 
                                   c=sample_stations['operator_count'], cmap='viridis', 
                                   alpha=0.6, s=20)
        axes[1, 1].set_title('RÃ©partition gÃ©ographique (Ã©chantillon)')
        axes[1, 1].set_xlabel('Longitude')
        axes[1, 1].set_ylabel('Latitude')
        plt.colorbar(scatter, ax=axes[1, 1], label='Nb opÃ©rateurs')
        
        plt.tight_layout()
        plt.show()
    
    def export_results(self, filename='stations_communes_resultats.csv'):
        """
        Exporte les rÃ©sultats vers un fichier CSV.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        # PrÃ©parer les donnÃ©es pour l'export
        export_data = self.common_stations.copy()
        export_data['operators_list'] = export_data['operators'].apply(lambda x: ' | '.join(x))
        
        export_columns = ['commune', 'department', 'region', 'latitude', 'longitude', 
                         'operator_count', 'operators_list', 'site_count']
        
        export_data[export_columns].to_csv(filename, index=False, sep=';', encoding='utf-8')
        print(f"ğŸ’¾ RÃ©sultats exportÃ©s vers {filename}")
    
    def generate_summary_report(self):
        """
        GÃ©nÃ¨re un rapport de synthÃ¨se complet.
        """
        if self.data is None or len(self.data) == 0:
            print("âŒ Aucune donnÃ©e disponible pour gÃ©nÃ©rer le rapport")
            return
            
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\n" + "="*60)
        print("ğŸ“‹ RAPPORT DE SYNTHÃˆSE - STATIONS TÃ‰LÃ‰COM COMMUNES")
        print("="*60)
        
        print(f"\nğŸ“Š STATISTIQUES GÃ‰NÃ‰RALES:")
        print(f"   â€¢ Sites totaux analysÃ©s: {len(self.data):,}")
        print(f"   â€¢ Stations communes identifiÃ©es: {len(self.common_stations):,}")
        
        if len(self.data) > 0:
            print(f"   â€¢ Pourcentage de mutualisation: {len(self.common_stations)/len(self.data)*100:.1f}%")
        else:
            print(f"   â€¢ Pourcentage de mutualisation: 0.0%")
            
        print(f"   â€¢ OpÃ©rateurs uniques: {self.data['nom_op'].nunique()}")
        
        if len(self.common_stations) > 0:
            print(f"   â€¢ DÃ©partements concernÃ©s: {self.common_stations['department'].nunique()}")
            
            print(f"\nğŸ¯ ANALYSE DES PARTAGES:")
            operator_count_dist = self.common_stations['operator_count'].value_counts()
            for count, freq in operator_count_dist.items():
                print(f"   â€¢ {freq} stations partagÃ©es par {count} opÃ©rateurs")
            
            print(f"\nğŸ† TOP 5 OPÃ‰RATEURS (stations communes):")
            operator_stats = self.analyze_by_operator().head(5)
            for _, row in operator_stats.iterrows():
                print(f"   â€¢ {row['OpÃ©rateur']}: {row['Stations_Communes']} stations")
            
            print(f"\nğŸ—ºï¸ TOP 5 DÃ‰PARTEMENTS:")
            dept_stats = self.analyze_by_department().head(5)
            for _, row in dept_stats.iterrows():
                print(f"   â€¢ {row['DÃ©partement']}: {row['Stations_Communes']} stations ({row['Pourcentage']}%)")
        else:
            print(f"   â€¢ Aucune station commune dÃ©tectÃ©e avec coordonnÃ©es exactes")
            
            # Diagnostics supplÃ©mentaires
            print(f"\nğŸ” DIAGNOSTICS:")
            print(f"   â€¢ OpÃ©rateurs uniques dans les donnÃ©es: {list(self.data['nom_op'].unique())}")
            print(f"   â€¢ Sites totaux: {len(self.data):,}")
            print(f"   â€¢ CoordonnÃ©es uniques: {self.data['coord_key'].nunique():,}")
            
            # VÃ©rifier s'il y a des coordonnÃ©es dupliquÃ©es (mÃªme si mÃªme opÃ©rateur)
            coord_counts = self.data['coord_key'].value_counts()
            duplicated_coords = coord_counts[coord_counts > 1]
            
            if len(duplicated_coords) > 0:
                print(f"   â€¢ {len(duplicated_coords)} coordonnÃ©es avec plusieurs sites (mÃªme opÃ©rateur ou diffÃ©rents)")
                print(f"   â€¢ Exemple de coordonnÃ©es dupliquÃ©es:")
                for coord, count in duplicated_coords.head(3).items():
                    sample_sites = self.data[self.data['coord_key'] == coord]
                    operators_at_coord = sample_sites['nom_op'].unique()
                    lat, lon = coord.split('_')
                    print(f"     - {lat}, {lon}: {count} sites, opÃ©rateurs: {list(operators_at_coord)}")
            else:
                print(f"   â€¢ Aucune coordonnÃ©e dupliquÃ©e trouvÃ©e - chaque site a des coordonnÃ©es uniques")
                print(f"   â€¢ Cela signifie qu'il n'y a pas de partage d'infrastructure dÃ©tectable")
            
            # Suggestion d'analyse alternative
            print(f"\nğŸ’¡ SUGGESTION:")  
            print(f"   â€¢ VÃ©rifiez si le fichier contient une colonne 'id_site_partage' ou similaire")
            print(f"   â€¢ Cette colonne pourrait indiquer les sites partagÃ©s mÃªme avec coordonnÃ©es diffÃ©rentes")



def main():
    """
    Fonction principale pour exÃ©cuter l'analyse complÃ¨te.
    """
    # Chemin vers votre fichier CSV - MODIFIEZ CE CHEMIN
    csv_file = "2023_T4_sites_Metropole.csv"
    
    print("ğŸ—¼ ANALYSEUR DE STATIONS TÃ‰LÃ‰COM COMMUNES")
    print("="*50)
    
    # CrÃ©er l'analyseur
    analyzer = TelecomAnalyzer(csv_file)
    
    # Charger les donnÃ©es avec diagnostic dÃ©taillÃ©
    if not analyzer.load_data():
        print("\nâŒ Ã‰chec du chargement des donnÃ©es.")
        print("ğŸ”§ Solutions possibles:")
        print("   1. VÃ©rifiez le chemin du fichier CSV")
        print("   2. VÃ©rifiez l'encodage du fichier (UTF-8, Latin-1, etc.)")
        print("   3. VÃ©rifiez le sÃ©parateur (';' ou ',')")
        print("   4. VÃ©rifiez que les colonnes requises existent:")
        print("      - latitude, longitude, nom_op, nom_dep")
        return
    
    # Effectuer l'analyse complÃ¨te
    analyzer.find_common_stations()
    analyzer.generate_summary_report()
    
    # Si des stations communes sont trouvÃ©es, continuer l'analyse
    if len(analyzer.common_stations) > 0:
        # Analyses dÃ©taillÃ©es
        print("\n" + "="*60)
        analyzer.analyze_by_operator()
        analyzer.analyze_by_department()
        analyzer.get_top_shared_stations()
        
        # CrÃ©er les visualisations
        try:
            print("\nğŸ“ˆ GÃ©nÃ©ration des graphiques...")
            analyzer.create_visualizations()
        except Exception as e:
            print(f"âš ï¸ Erreur lors de la crÃ©ation des graphiques: {e}")
        
        # 4. Matrice de partage entre opÃ©rateurs
        sharing_matrix = analyzer.create_operator_sharing_matrix()
        if sharing_matrix is not None:
            # Afficher la matrice dans la console
            analyzer.print_matrix_table(sharing_matrix)
            # CrÃ©er le graphique
            analyzer.visualize_sharing_matrix(sharing_matrix)
        
        # 5. Analyse des paires d'opÃ©rateurs
        analyzer.analyze_operator_pairs()
        
        # Exporter les rÃ©sultats
        try:
            analyzer.export_results()
        except Exception as e:
            print(f"âš ï¸ Erreur lors de l'export: {e}")
    else:
        print("\nğŸ’¡ SUGGESTIONS POUR TROUVER DES STATIONS COMMUNES:")
        print("   1. Augmentez la tolÃ©rance: analyzer.tolerance = 0.001")
        print("   2. VÃ©rifiez que plusieurs opÃ©rateurs sont prÃ©sents")
        print("   3. Examinez la qualitÃ© des coordonnÃ©es GPS")
    
    print("\nâœ… Analyse terminÃ©e!")


# FONCTION DE DIAGNOSTIC SUPPLÃ‰MENTAIRE
def diagnose_csv(csv_file):
    """
    Fonction utilitaire pour diagnostiquer un fichier CSV problÃ©matique.
    """
    import os
    
    print(f"ğŸ” DIAGNOSTIC DU FICHIER: {csv_file}")
    print("="*50)
    
    if not os.path.exists(csv_file):
        print(f"âŒ Fichier non trouvÃ©: {csv_file}")
        return
    
    # Informations sur le fichier
    file_size = os.path.getsize(csv_file) / (1024*1024)  # MB
    print(f"ğŸ“„ Taille du fichier: {file_size:.1f} MB")
    
    # Lire les premiÃ¨res lignes
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            lines = [f.readline().strip() for _ in range(5)]
        print(f"ğŸ“‹ PremiÃ¨res lignes (UTF-8):")
        for i, line in enumerate(lines):
            print(f"   {i+1}: {line[:100]}...")
    except:
        try:
            with open(csv_file, 'r', encoding='latin-1') as f:
                lines = [f.readline().strip() for _ in range(5)]
            print(f"ğŸ“‹ PremiÃ¨res lignes (Latin-1):")
            for i, line in enumerate(lines):
                print(f"   {i+1}: {line[:100]}...")
        except Exception as e:
            print(f"âŒ Impossible de lire le fichier: {e}")
    
    # DÃ©tecter le sÃ©parateur probable
    if lines:
        separators = [';', ',', '\t', '|']
        separator_counts = {sep: lines[0].count(sep) for sep in separators}
        likely_sep = max(separator_counts, key=separator_counts.get)
        print(f"ğŸ” SÃ©parateur probable: '{likely_sep}' ({separator_counts[likely_sep]} occurrences)")
        
        columns = lines[0].split(likely_sep)
        print(f"ğŸ“Š Colonnes dÃ©tectÃ©es ({len(columns)}): {columns[:5]}...")


# DÃ©commentez cette ligne pour diagnostiquer votre fichier
# diagnose_csv("2023_T4_sites_Metropole.csv")


if __name__ == "__main__":
    main()


# EXEMPLE DE MATRICE DE PARTAGE RÃ‰SULTANTE:
"""
ğŸ“‹ MATRICE DE PARTAGE ENTRE OPÃ‰RATEURS:
(Nombre de stations communes par paire d'opÃ©rateurs)

           Orange  SFR  Free  Bouygues
Orange         0   45    23        18
SFR           45    0    31        22  
Free          23   31     0        15
Bouygues      18   22    15         0

ğŸ¯ STATISTIQUES DE PARTAGE:
ğŸ† Paire avec le plus de partage (45 stations):
   â€¢ Orange â†” SFR: 45 stations communes

ğŸ“Š Total de partages par opÃ©rateur:
   â€¢ Orange: 86 partages
   â€¢ SFR: 98 partages  
   â€¢ Free: 69 partages
   â€¢ Bouygues: 55 partages

ğŸ“Š TOP 10 DES PAIRES D'OPÃ‰RATEURS:
 1. Orange + SFR: 45 stations communes
    ğŸ“ Paris 15e (Paris)
    ğŸ“ Lyon 3e (RhÃ´ne)
    ğŸ“ Marseille 8e (Bouches-du-RhÃ´ne)
    ... et 42 autres stations

 2. Free + SFR: 31 stations communes
    ğŸ“ Toulouse 1er (Haute-Garonne)
    ğŸ“ Nice (Alpes-Maritimes)
    ... et 29 autres stations
"""