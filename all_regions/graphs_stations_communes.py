import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')

class TelecomAnalyzer:
    def __init__(self, csv_file_path):
        """
        Initialise l'analyseur avec le fichier CSV des sites t√©l√©com.
        
        Args:
            csv_file_path (str): Chemin vers le fichier CSV
        """
        self.csv_file_path = csv_file_path
        self.data = None
        self.common_stations = None
        self.exact_match = True  # Comparaison exacte des coordonn√©es
        
    def load_data(self):
        """
        Charge et nettoie les donn√©es du fichier CSV d√©limit√© par des points-virgules.
        """
        print("üìÇ Chargement des donn√©es (format point-virgule)...")
        
        try:
            # V√©rifier si le fichier existe
            import os
            if not os.path.exists(self.csv_file_path):
                print(f"‚ùå Fichier non trouv√©: {self.csv_file_path}")
                return False
            
            print(f"üìÑ Fichier trouv√©: {self.csv_file_path}")
            file_size = os.path.getsize(self.csv_file_path) / (1024*1024)
            print(f"üìè Taille: {file_size:.1f} MB")
            
            # Charger avec point-virgule comme s√©parateur
            print("üîÑ Chargement avec d√©limiteur ';'...")
            
            # Essayer diff√©rents encodages pour les fichiers fran√ßais
            encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings_to_try:
                try:
                    print(f"   Essai avec encoding: {encoding}")
                    self.data = pd.read_csv(
                        self.csv_file_path, 
                        sep=';',  # Point-virgule explicite
                        encoding=encoding,
                        low_memory=False,
                        on_bad_lines='skip'  # Ignorer les lignes malform√©es
                    )
                    
                    print(f"   ‚úÖ Charg√© avec {encoding}: {len(self.data)} lignes")
                    break
                    
                except UnicodeDecodeError:
                    print(f"   ‚ùå √âchec encoding {encoding}")
                    continue
                except Exception as e:
                    print(f"   ‚ùå Erreur avec {encoding}: {e}")
                    continue
            else:
                print("‚ùå Tous les encodages ont √©chou√©")
                return False
            
            print(f"üìä Lignes brutes charg√©es: {len(self.data):,}")
            
            # Nettoyer les noms de colonnes
            print("üßπ Nettoyage des colonnes...")
            original_columns = list(self.data.columns)
            self.data.columns = [col.strip() for col in self.data.columns]
            
            print(f"üìã Colonnes disponibles: {list(self.data.columns)}")
            
            # V√©rifier les colonnes n√©cessaires
            required_columns = ['latitude', 'longitude', 'nom_op', 'nom_dep']
            available_columns = list(self.data.columns)
            
            print(f"üîç V√©rification des colonnes requises:")
            missing_columns = []
            for col in required_columns:
                if col in available_columns:
                    print(f"   ‚úÖ {col}: trouv√©e")
                else:
                    print(f"   ‚ùå {col}: MANQUANTE")
                    # Chercher des colonnes similaires
                    similar = [c for c in available_columns if col.lower() in c.lower() or c.lower() in col.lower()]
                    if similar:
                        print(f"      Colonnes similaires: {similar}")
                    missing_columns.append(col)
            
            if missing_columns:
                print(f"‚ùå Colonnes manquantes critiques: {missing_columns}")
                print(f"üí° Colonnes disponibles dans le fichier:")
                for i, col in enumerate(available_columns, 1):
                    print(f"   {i:2d}. {col}")
                return False
            
            # Nettoyer les donn√©es √©tape par √©tape
            print(f"\nüßπ Nettoyage des donn√©es:")
            initial_count = len(self.data)
            print(f"   D√©part: {initial_count:,} lignes")
            
            # Supprimer les lignes vides dans les colonnes critiques
            for col in required_columns:
                before = len(self.data)
                # Supprimer les NaN et les cha√Ænes vides
                self.data = self.data[
                    self.data[col].notna() & 
                    (self.data[col] != '') & 
                    (self.data[col] != ' ')
                ]
                after = len(self.data)
                if before != after:
                    print(f"   Apr√®s nettoyage '{col}': {after:,} lignes (-{before-after:,})")
            
            if len(self.data) == 0:
                print("‚ùå Aucune ligne valide apr√®s nettoyage des valeurs manquantes")
                return False
            
            # Convertir les coordonn√©es en num√©rique
            print("üî¢ Conversion des coordonn√©es GPS...")
            
            # Remplacer les virgules par des points si n√©cessaire (format fran√ßais)
            if self.data['latitude'].dtype == 'object':
                self.data['latitude'] = self.data['latitude'].astype(str).str.replace(',', '.')
            if self.data['longitude'].dtype == 'object':
                self.data['longitude'] = self.data['longitude'].astype(str).str.replace(',', '.')
            
            self.data['latitude'] = pd.to_numeric(self.data['latitude'], errors='coerce')
            self.data['longitude'] = pd.to_numeric(self.data['longitude'], errors='coerce')
            
            # V√©rifier les conversions
            lat_invalid = self.data['latitude'].isna().sum()
            lon_invalid = self.data['longitude'].isna().sum()
            if lat_invalid > 0:
                print(f"   ‚ö†Ô∏è {lat_invalid} latitudes invalides d√©tect√©es")
            if lon_invalid > 0:
                print(f"   ‚ö†Ô∏è {lon_invalid} longitudes invalides d√©tect√©es")
            
            # Supprimer les coordonn√©es invalides
            before = len(self.data)
            self.data = self.data.dropna(subset=['latitude', 'longitude'])
            after = len(self.data)
            if before != after:
                print(f"   Apr√®s suppression coordonn√©es invalides: {after:,} lignes (-{before-after:,})")
            
            # Filtrer les coordonn√©es dans la plage de la France m√©tropolitaine
            before = len(self.data)
            france_filter = (
                (self.data['latitude'].between(41.0, 51.5)) &
                (self.data['longitude'].between(-5.5, 9.5))
            )
            self.data = self.data[france_filter]
            after = len(self.data)
            if before != after:
                print(f"   Apr√®s filtrage g√©ographique France: {after:,} lignes (-{before-after:,})")
            
            if len(self.data) == 0:
                print("‚ùå Aucune donn√©e valide apr√®s filtrage g√©ographique")
                return False
            
            # Statistiques finales
            print(f"\n‚úÖ Donn√©es charg√©es avec succ√®s:")
            print(f"   üìä Sites totaux: {len(self.data):,}")
            print(f"   üè¢ Op√©rateurs uniques: {self.data['nom_op'].nunique()}")
            print(f"   üó∫Ô∏è D√©partements uniques: {self.data['nom_dep'].nunique()}")
            
            # Afficher les op√©rateurs
            operators = self.data['nom_op'].unique()
            print(f"   üì° Op√©rateurs: {', '.join(operators)}")
            
            # Afficher quelques d√©partements
            departments = self.data['nom_dep'].unique()[:10]
            print(f"   üèõÔ∏è Premiers d√©partements: {', '.join(departments)}")
            
            # √âchantillon des donn√©es
            print(f"\nüìã √âchantillon des donn√©es:")
            sample = self.data[['nom_op', 'nom_dep', 'latitude', 'longitude']].head(3)
            for idx, row in sample.iterrows():
                print(f"   {row['nom_op']} | {row['nom_dep']} | {row['latitude']:.5f}, {row['longitude']:.5f}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def find_common_stations(self):
        """
        Identifie les stations communes par comparaison EXACTE des coordonn√©es GPS.
        Une station commune = m√™mes coordonn√©es latitude/longitude exactes.
        """
        print("üîç Recherche des stations communes (coordonn√©es exactes)...")
        
        # Cr√©er une cl√© unique bas√©e sur les coordonn√©es exactes
        self.data['coord_key'] = self.data['latitude'].astype(str) + '_' + self.data['longitude'].astype(str)
        
        print(f"üìä Coordonn√©es uniques trouv√©es: {self.data['coord_key'].nunique():,}")
        
        # Grouper par coordonn√©es exactes
        location_groups = self.data.groupby('coord_key')
        
        common_stations_list = []
        multiple_sites_same_coords = 0
        multiple_operators_same_coords = 0
        
        for coord_key, group in location_groups:
            if len(group) > 1:  # Plusieurs sites aux m√™mes coordonn√©es
                multiple_sites_same_coords += 1
                operators = group['nom_op'].unique()
                
                if len(operators) > 1:  # Plusieurs op√©rateurs diff√©rents
                    multiple_operators_same_coords += 1
                    
                    station_info = {
                        'coord_key': coord_key,
                        'latitude': group['latitude'].iloc[0],  # Coordonn√©es exactes
                        'longitude': group['longitude'].iloc[0],
                        'operators': list(operators),
                        'operator_count': len(operators),
                        'site_count': len(group),
                        'department': group['nom_dep'].iloc[0],
                        'region': group['nom_reg'].iloc[0] if 'nom_reg' in group.columns else 'N/A',
                        'commune': group['nom_com'].iloc[0] if 'nom_com' in group.columns else 'N/A',
                        'sites_details': group[['nom_op', 'num_site']].to_dict('records') if 'num_site' in group.columns else []
                    }
                    common_stations_list.append(station_info)
        
        self.common_stations = pd.DataFrame(common_stations_list)
        
        print(f"üìç R√©sultats de l'analyse:")
        print(f"   ‚Ä¢ {multiple_sites_same_coords:,} coordonn√©es avec plusieurs sites")
        print(f"   ‚Ä¢ {multiple_operators_same_coords:,} coordonn√©es avec plusieurs op√©rateurs")
        print(f"   ‚Ä¢ {len(self.common_stations):,} stations communes identifi√©es")
        
        if len(self.common_stations) > 0:
            # Statistiques sur le partage
            max_operators = self.common_stations['operator_count'].max()
            avg_operators = self.common_stations['operator_count'].mean()
            print(f"   ‚Ä¢ Maximum d'op√©rateurs sur une station: {max_operators}")
            print(f"   ‚Ä¢ Moyenne d'op√©rateurs par station commune: {avg_operators:.1f}")
        
        return self.common_stations
    
    def analyze_by_operator(self):
        """
        Analyse les statistiques par op√©rateur.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\nüìà Analyse par op√©rateur:")
        
        # Compter les occurrences de chaque op√©rateur dans les stations communes
        operator_counts = defaultdict(int)
        
        for _, station in self.common_stations.iterrows():
            for operator in station['operators']:
                operator_counts[operator] += 1
        
        operator_stats = pd.DataFrame(list(operator_counts.items()), 
                                    columns=['Op√©rateur', 'Stations_Communes'])
        operator_stats = operator_stats.sort_values('Stations_Communes', ascending=False)
        
        print(operator_stats.to_string(index=False))
        
        return operator_stats
    
    def analyze_by_department(self):
        """
        Analyse les statistiques par d√©partement.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\nüó∫Ô∏è Analyse par d√©partement:")
        
        dept_stats = self.common_stations['department'].value_counts().head(15)
        dept_df = pd.DataFrame({
            'D√©partement': dept_stats.index,
            'Stations_Communes': dept_stats.values,
            'Pourcentage': (dept_stats.values / len(self.common_stations) * 100).round(1)
        })
        
        print(dept_df.to_string(index=False))
        
        return dept_df
    
    def create_operator_sharing_matrix(self):
        """
        Cr√©e une matrice montrant combien de stations communes chaque paire d'op√©rateurs partage.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("‚ùå Aucune station commune pour cr√©er la matrice")
            return None
        
        print("üìä Cr√©ation de la matrice de partage entre op√©rateurs...")
        
        # Obtenir tous les op√©rateurs uniques
        all_operators = sorted(list(set([op for station in self.common_stations['operators'] for op in station])))
        
        print(f"   Op√©rateurs d√©tect√©s: {all_operators}")
        
        # Cr√©er une matrice vide
        matrix = pd.DataFrame(0, index=all_operators, columns=all_operators)
        
        # Remplir la matrice
        for _, station in self.common_stations.iterrows():
            operators = station['operators']
            # Pour chaque paire d'op√©rateurs dans cette station
            for i, op1 in enumerate(operators):
                for j, op2 in enumerate(operators):
                    if i != j:  # √âviter de compter un op√©rateur avec lui-m√™me
                        matrix.loc[op1, op2] += 1
        
        # La matrice est sym√©trique, donc diviser par 2 pour √©viter le double comptage
        # Mais garder la diagonale √† 0
        for i in range(len(all_operators)):
            for j in range(i+1, len(all_operators)):
                op1, op2 = all_operators[i], all_operators[j]
                shared_count = matrix.loc[op1, op2]
                matrix.loc[op1, op2] = shared_count
                matrix.loc[op2, op1] = shared_count
        
        print(f"‚úÖ Matrice de partage cr√©√©e ({len(all_operators)}x{len(all_operators)})")
        
        # Afficher la matrice
        print(f"\nüìã MATRICE DE PARTAGE ENTRE OP√âRATEURS:")
        print(f"   (Nombre de stations communes par paire d'op√©rateurs)")
        print(matrix)
        
        # Statistiques int√©ressantes
        print(f"\nüéØ STATISTIQUES DE PARTAGE:")
        
        # Paires les plus partag√©es
        upper_triangle = matrix.where(np.triu(np.ones(matrix.shape), k=1).astype(bool))
        max_sharing = upper_triangle.max().max()
        
        if max_sharing > 0:
            max_pairs = []
            for col in upper_triangle.columns:
                for idx in upper_triangle.index:
                    if upper_triangle.loc[idx, col] == max_sharing:
                        max_pairs.append((idx, col, max_sharing))
            
            print(f"   üèÜ Paire(s) avec le plus de partage ({max_sharing} stations):")
            for op1, op2, count in max_pairs:
                print(f"      ‚Ä¢ {op1} ‚Üî {op2}: {count} stations communes")
        
        # Total de partages par op√©rateur
        sharing_totals = matrix.sum(axis=1) / 2  # Diviser par 2 car matrice sym√©trique
        sharing_totals = sharing_totals.sort_values(ascending=False)
        
        print(f"\n   üìä Total de partages par op√©rateur:")
        for op, total in sharing_totals.items():
            print(f"      ‚Ä¢ {op}: {int(total)} partages")
        
        return matrix
    
    def visualize_sharing_matrix(self, matrix=None):
        """
        Cr√©e une heatmap de la matrice de partage.
        """
        if matrix is None:
            matrix = self.create_operator_sharing_matrix()
        
        if matrix is None:
            return
        
        try:
            # Essayer avec seaborn (plus joli)
            plt.figure(figsize=(10, 8))
            
            sns.heatmap(matrix, 
                       annot=True,  # Afficher les valeurs
                       fmt='d',     # Format entier
                       cmap='Blues', 
                       square=True,
                       cbar_kws={'label': 'Nombre de stations communes'},
                       linewidths=0.5)
            
            plt.title('Matrice de Partage entre Op√©rateurs\n(Nombre de stations communes)', 
                     fontsize=14, fontweight='bold', pad=20)
            plt.xlabel('Op√©rateurs', fontweight='bold')
            plt.ylabel('Op√©rateurs', fontweight='bold')
            
            # Rotation des labels pour une meilleure lisibilit√©
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            
            plt.tight_layout()
            plt.show()
            
        except ImportError:
            print("‚ö†Ô∏è Seaborn non disponible, cr√©ation d'une heatmap simple...")
            self._create_simple_matrix_plot(matrix)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur avec seaborn: {e}")
            self._create_simple_matrix_plot(matrix)
    
    def _create_simple_matrix_plot(self, matrix):
        """
        Cr√©e une heatmap simple avec matplotlib seulement.
        """
        plt.figure(figsize=(10, 8))
        
        # Cr√©er la heatmap avec matplotlib
        im = plt.imshow(matrix.values, cmap='Blues', aspect='auto')
        
        # Ajouter les valeurs sur chaque case
        for i in range(len(matrix.index)):
            for j in range(len(matrix.columns)):
                plt.text(j, i, int(matrix.iloc[i, j]), 
                        ha='center', va='center', fontweight='bold')
        
        # Configuration des axes
        plt.xticks(range(len(matrix.columns)), matrix.columns, rotation=45, ha='right')
        plt.yticks(range(len(matrix.index)), matrix.index)
        
        plt.title('Matrice de Partage entre Op√©rateurs\n(Nombre de stations communes)', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('Op√©rateurs', fontweight='bold')
        plt.ylabel('Op√©rateurs', fontweight='bold')
        
        # Ajouter une barre de couleur
        cbar = plt.colorbar(im)
        cbar.set_label('Nombre de stations communes', rotation=270, labelpad=20)
        
        plt.tight_layout()
        plt.show()
    
    def print_matrix_table(self, matrix=None):
        """
        Affiche la matrice sous forme de tableau bien format√© dans la console.
        """
        if matrix is None:
            matrix = self.create_operator_sharing_matrix()
        
        if matrix is None:
            return
        
        print("\n" + "="*80)
        print("üìä MATRICE DE PARTAGE ENTRE OP√âRATEURS")
        print("="*80)
        print("(Nombre de stations communes par paire d'op√©rateurs)")
        print()
        
        # Formatter pour un affichage propre
        operators = list(matrix.columns)
        
        # En-t√™te
        header = "           "
        for op in operators:
            header += f"{op:>8s} "
        print(header)
        print("-" * len(header))
        
        # Lignes de donn√©es
        for i, op1 in enumerate(operators):
            row = f"{op1:>10s} "
            for j, op2 in enumerate(operators):
                value = int(matrix.loc[op1, op2])
                if i == j:  # Diagonale
                    row += f"{'':>8s} "
                else:
                    row += f"{value:>8d} "
            print(row)
        
        print("\nüí° Lecture: La case (Ligne, Colonne) indique combien de stations")
        print("   les deux op√©rateurs partagent ensemble.")
        print("="*80)
    
    def analyze_operator_pairs(self):
        """
        Analyse d√©taill√©e des paires d'op√©rateurs qui partagent le plus.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("‚ùå Aucune donn√©e pour l'analyse des paires")
            return None
        
        print("üîç Analyse d√©taill√©e des paires d'op√©rateurs...")
        
        # Compter les occurrences de chaque paire
        pair_counts = {}
        pair_stations = {}  # Pour stocker les d√©tails des stations
        
        for idx, station in self.common_stations.iterrows():
            operators = sorted(station['operators'])  # Tri pour coh√©rence
            station_info = {
                'commune': station['commune'],
                'department': station['department'],
                'latitude': station['latitude'],
                'longitude': station['longitude']
            }
            
            # G√©n√©rer toutes les paires possibles
            from itertools import combinations
            for pair in combinations(operators, 2):
                pair_key = f"{pair[0]} + {pair[1]}"
                
                if pair_key not in pair_counts:
                    pair_counts[pair_key] = 0
                    pair_stations[pair_key] = []
                
                pair_counts[pair_key] += 1
                pair_stations[pair_key].append(station_info)
        
        # Convertir en DataFrame et trier
        pairs_df = pd.DataFrame(list(pair_counts.items()), 
                               columns=['Paire_Op√©rateurs', 'Stations_Communes'])
        pairs_df = pairs_df.sort_values('Stations_Communes', ascending=False)
        
        print(f"\nüìä TOP 10 DES PAIRES D'OP√âRATEURS:")
        for idx, row in pairs_df.head(10).iterrows():
            pair_name = row['Paire_Op√©rateurs']
            count = row['Stations_Communes']
            print(f"   {idx+1:2d}. {pair_name}: {count} stations communes")
            
            # Afficher quelques exemples de stations
            if count <= 3:  # Si peu de stations, afficher toutes
                stations = pair_stations[pair_name]
                for station in stations:
                    print(f"       üìç {station['commune']} ({station['department']})")
            else:  # Sinon, afficher les 3 premi√®res
                stations = pair_stations[pair_name][:3]
                for station in stations:
                    print(f"       üìç {station['commune']} ({station['department']})")
                if count > 3:
                    print(f"       ... et {count-3} autres stations")
            print()
        
        return pairs_df, pair_stations
        """
        Analyse alternative utilisant la colonne id_site_partage si disponible.
        """
        if 'id_site_partage' not in self.data.columns:
            print("‚ùå Colonne 'id_site_partage' non disponible")
            return None
        
        print("üîç Analyse par id_site_partage...")
        
        # Filtrer les sites avec un ID de partage
        shared_sites = self.data[self.data['id_site_partage'].notna() & (self.data['id_site_partage'] != '')]
        
        if len(shared_sites) == 0:
            print("‚ùå Aucun site avec id_site_partage renseign√©")
            return None
        
        print(f"üìä {len(shared_sites)} sites avec id_site_partage")
        
        # Grouper par ID de partage
        sharing_groups = shared_sites.groupby('id_site_partage')
        
        shared_infrastructure = []
        
        for share_id, group in sharing_groups:
            if len(group) > 1:
                operators = group['nom_op'].unique()
                if len(operators) > 1:
                    shared_info = {
                        'share_id': share_id,
                        'operators': list(operators),
                        'operator_count': len(operators),
                        'site_count': len(group),
                        'departments': list(group['nom_dep'].unique()),
                        'coordinates': list(group[['latitude', 'longitude']].drop_duplicates().values)
                    }
                    shared_infrastructure.append(shared_info)
        
        print(f"üéØ {len(shared_infrastructure)} infrastructures partag√©es via id_site_partage")
        
        return pd.DataFrame(shared_infrastructure)
    def get_top_shared_stations(self, n=20):
        """
        Retourne les stations avec le plus d'op√©rateurs.
        """
        if self.common_stations is None or len(self.common_stations) == 0:
            print("‚ùå Aucune station commune √† afficher")
            return pd.DataFrame()
        
        top_stations = self.common_stations.nlargest(n, 'operator_count')[
            ['commune', 'department', 'operator_count', 'operators', 'latitude', 'longitude', 'site_count']
        ]
        
        print(f"\nüèÜ Top {min(n, len(top_stations))} des stations avec le plus d'op√©rateurs (coordonn√©es exactes):")
        for idx, station in top_stations.iterrows():
            operators_str = ', '.join(station['operators'])
            print(f"   üìç {station['commune']} ({station['department']})")
            print(f"      üè¢ {station['operator_count']} op√©rateurs: {operators_str}")
            print(f"      üìä {station['site_count']} sites | üó∫Ô∏è {station['latitude']:.6f}, {station['longitude']:.6f}")
            print()
        
        return top_stations
    
    def create_visualizations(self):
        """
        Cr√©e les graphiques d'analyse.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        # Configuration des graphiques
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('üìä Analyse des Stations T√©l√©com Communes', fontsize=16, fontweight='bold')
        
        # 1. Stations communes par op√©rateur
        operator_stats = self.analyze_by_operator()
        axes[0, 0].bar(operator_stats['Op√©rateur'], operator_stats['Stations_Communes'], 
                       color='skyblue', edgecolor='navy')
        axes[0, 0].set_title('Stations communes par op√©rateur')
        axes[0, 0].set_xlabel('Op√©rateur')
        axes[0, 0].set_ylabel('Nombre de stations communes')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. Top 10 d√©partements
        dept_stats = self.analyze_by_department().head(10)
        axes[0, 1].barh(dept_stats['D√©partement'], dept_stats['Stations_Communes'], 
                        color='lightcoral')
        axes[0, 1].set_title('Top 10 d√©partements - Stations communes')
        axes[0, 1].set_xlabel('Nombre de stations communes')
        
        # 3. Distribution du nombre d'op√©rateurs par station
        operator_count_dist = self.common_stations['operator_count'].value_counts().sort_index()
        axes[1, 0].bar(operator_count_dist.index, operator_count_dist.values, 
                       color='lightgreen', edgecolor='darkgreen')
        axes[1, 0].set_title('Distribution: Nombre d\'op√©rateurs par station')
        axes[1, 0].set_xlabel('Nombre d\'op√©rateurs')
        axes[1, 0].set_ylabel('Nombre de stations')
        
        # 4. R√©partition g√©ographique (sample)
        sample_stations = self.common_stations.sample(min(1000, len(self.common_stations)))
        scatter = axes[1, 1].scatter(sample_stations['longitude'], sample_stations['latitude'], 
                                   c=sample_stations['operator_count'], cmap='viridis', 
                                   alpha=0.6, s=20)
        axes[1, 1].set_title('R√©partition g√©ographique (√©chantillon)')
        axes[1, 1].set_xlabel('Longitude')
        axes[1, 1].set_ylabel('Latitude')
        plt.colorbar(scatter, ax=axes[1, 1], label='Nb op√©rateurs')
        
        plt.tight_layout()
        plt.show()
    
    def export_results(self, filename='stations_communes_resultats.csv'):
        """
        Exporte les r√©sultats vers un fichier CSV.
        """
        if self.common_stations is None:
            self.find_common_stations()
        
        # Pr√©parer les donn√©es pour l'export
        export_data = self.common_stations.copy()
        export_data['operators_list'] = export_data['operators'].apply(lambda x: ' | '.join(x))
        
        export_columns = ['commune', 'department', 'region', 'latitude', 'longitude', 
                         'operator_count', 'operators_list', 'site_count']
        
        export_data[export_columns].to_csv(filename, index=False, sep=';', encoding='utf-8')
        print(f"üíæ R√©sultats export√©s vers {filename}")
    
    def generate_summary_report(self):
        """
        G√©n√®re un rapport de synth√®se complet.
        """
        if self.data is None or len(self.data) == 0:
            print("‚ùå Aucune donn√©e disponible pour g√©n√©rer le rapport")
            return
            
        if self.common_stations is None:
            self.find_common_stations()
        
        print("\n" + "="*60)
        print("üìã RAPPORT DE SYNTH√àSE - STATIONS T√âL√âCOM COMMUNES")
        print("="*60)
        
        print(f"\nüìä STATISTIQUES G√âN√âRALES:")
        print(f"   ‚Ä¢ Sites totaux analys√©s: {len(self.data):,}")
        print(f"   ‚Ä¢ Stations communes identifi√©es: {len(self.common_stations):,}")
        
        if len(self.data) > 0:
            print(f"   ‚Ä¢ Pourcentage de mutualisation: {len(self.common_stations)/len(self.data)*100:.1f}%")
        else:
            print(f"   ‚Ä¢ Pourcentage de mutualisation: 0.0%")
            
        print(f"   ‚Ä¢ Op√©rateurs uniques: {self.data['nom_op'].nunique()}")
        
        if len(self.common_stations) > 0:
            print(f"   ‚Ä¢ D√©partements concern√©s: {self.common_stations['department'].nunique()}")
            
            print(f"\nüéØ ANALYSE DES PARTAGES:")
            operator_count_dist = self.common_stations['operator_count'].value_counts()
            for count, freq in operator_count_dist.items():
                print(f"   ‚Ä¢ {freq} stations partag√©es par {count} op√©rateurs")
            
            print(f"\nüèÜ TOP 5 OP√âRATEURS (stations communes):")
            operator_stats = self.analyze_by_operator().head(5)
            for _, row in operator_stats.iterrows():
                print(f"   ‚Ä¢ {row['Op√©rateur']}: {row['Stations_Communes']} stations")
            
            print(f"\nüó∫Ô∏è TOP 5 D√âPARTEMENTS:")
            dept_stats = self.analyze_by_department().head(5)
            for _, row in dept_stats.iterrows():
                print(f"   ‚Ä¢ {row['D√©partement']}: {row['Stations_Communes']} stations ({row['Pourcentage']}%)")
        else:
            print(f"   ‚Ä¢ Aucune station commune d√©tect√©e avec coordonn√©es exactes")
            
            # Diagnostics suppl√©mentaires
            print(f"\nüîç DIAGNOSTICS:")
            print(f"   ‚Ä¢ Op√©rateurs uniques dans les donn√©es: {list(self.data['nom_op'].unique())}")
            print(f"   ‚Ä¢ Sites totaux: {len(self.data):,}")
            print(f"   ‚Ä¢ Coordonn√©es uniques: {self.data['coord_key'].nunique():,}")
            
            # V√©rifier s'il y a des coordonn√©es dupliqu√©es (m√™me si m√™me op√©rateur)
            coord_counts = self.data['coord_key'].value_counts()
            duplicated_coords = coord_counts[coord_counts > 1]
            
            if len(duplicated_coords) > 0:
                print(f"   ‚Ä¢ {len(duplicated_coords)} coordonn√©es avec plusieurs sites (m√™me op√©rateur ou diff√©rents)")
                print(f"   ‚Ä¢ Exemple de coordonn√©es dupliqu√©es:")
                for coord, count in duplicated_coords.head(3).items():
                    sample_sites = self.data[self.data['coord_key'] == coord]
                    operators_at_coord = sample_sites['nom_op'].unique()
                    lat, lon = coord.split('_')
                    print(f"     - {lat}, {lon}: {count} sites, op√©rateurs: {list(operators_at_coord)}")
            else:
                print(f"   ‚Ä¢ Aucune coordonn√©e dupliqu√©e trouv√©e - chaque site a des coordonn√©es uniques")
                print(f"   ‚Ä¢ Cela signifie qu'il n'y a pas de partage d'infrastructure d√©tectable")
            
            # Suggestion d'analyse alternative
            print(f"\nüí° SUGGESTION:")  
            print(f"   ‚Ä¢ V√©rifiez si le fichier contient une colonne 'id_site_partage' ou similaire")
            print(f"   ‚Ä¢ Cette colonne pourrait indiquer les sites partag√©s m√™me avec coordonn√©es diff√©rentes")



def main():
    """
    Fonction principale pour ex√©cuter l'analyse compl√®te.
    """
    # Chemin vers votre fichier CSV - MODIFIEZ CE CHEMIN
    csv_file = "2023_T4_sites_Metropole.csv"
    
    print("üóº ANALYSEUR DE STATIONS T√âL√âCOM COMMUNES")
    print("="*50)
    
    # Cr√©er l'analyseur
    analyzer = TelecomAnalyzer(csv_file)
    
    # Charger les donn√©es avec diagnostic d√©taill√©
    if not analyzer.load_data():
        print("\n‚ùå √âchec du chargement des donn√©es.")
        print("üîß Solutions possibles:")
        print("   1. V√©rifiez le chemin du fichier CSV")
        print("   2. V√©rifiez l'encodage du fichier (UTF-8, Latin-1, etc.)")
        print("   3. V√©rifiez le s√©parateur (';' ou ',')")
        print("   4. V√©rifiez que les colonnes requises existent:")
        print("      - latitude, longitude, nom_op, nom_dep")
        return
    
    # Effectuer l'analyse compl√®te
    analyzer.find_common_stations()
    analyzer.generate_summary_report()
    
    # Si des stations communes sont trouv√©es, continuer l'analyse
    if len(analyzer.common_stations) > 0:
        # Analyses d√©taill√©es
        print("\n" + "="*60)
        analyzer.analyze_by_operator()
        analyzer.analyze_by_department()
        analyzer.get_top_shared_stations()
        
        # Cr√©er les visualisations
        try:
            print("\nüìà G√©n√©ration des graphiques...")
            analyzer.create_visualizations()
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la cr√©ation des graphiques: {e}")
        
        # 4. Matrice de partage entre op√©rateurs
        sharing_matrix = analyzer.create_operator_sharing_matrix()
        if sharing_matrix is not None:
            # Afficher la matrice dans la console
            analyzer.print_matrix_table(sharing_matrix)
            # Cr√©er le graphique
            analyzer.visualize_sharing_matrix(sharing_matrix)
        
        # 5. Analyse des paires d'op√©rateurs
        analyzer.analyze_operator_pairs()
        
        # Exporter les r√©sultats
        try:
            analyzer.export_results()
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de l'export: {e}")
    else:
        print("\nüí° SUGGESTIONS POUR TROUVER DES STATIONS COMMUNES:")
        print("   1. Augmentez la tol√©rance: analyzer.tolerance = 0.001")
        print("   2. V√©rifiez que plusieurs op√©rateurs sont pr√©sents")
        print("   3. Examinez la qualit√© des coordonn√©es GPS")
    
    print("\n‚úÖ Analyse termin√©e!")


# FONCTION DE DIAGNOSTIC SUPPL√âMENTAIRE
def diagnose_csv(csv_file):
    """
    Fonction utilitaire pour diagnostiquer un fichier CSV probl√©matique.
    """
    import os
    
    print(f"üîç DIAGNOSTIC DU FICHIER: {csv_file}")
    print("="*50)
    
    if not os.path.exists(csv_file):
        print(f"‚ùå Fichier non trouv√©: {csv_file}")
        return
    
    # Informations sur le fichier
    file_size = os.path.getsize(csv_file) / (1024*1024)  # MB
    print(f"üìÑ Taille du fichier: {file_size:.1f} MB")
    
    # Lire les premi√®res lignes
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            lines = [f.readline().strip() for _ in range(5)]
        print(f"üìã Premi√®res lignes (UTF-8):")
        for i, line in enumerate(lines):
            print(f"   {i+1}: {line[:100]}...")
    except:
        try:
            with open(csv_file, 'r', encoding='latin-1') as f:
                lines = [f.readline().strip() for _ in range(5)]
            print(f"üìã Premi√®res lignes (Latin-1):")
            for i, line in enumerate(lines):
                print(f"   {i+1}: {line[:100]}...")
        except Exception as e:
            print(f"‚ùå Impossible de lire le fichier: {e}")
    
    # D√©tecter le s√©parateur probable
    if lines:
        separators = [';', ',', '\t', '|']
        separator_counts = {sep: lines[0].count(sep) for sep in separators}
        likely_sep = max(separator_counts, key=separator_counts.get)
        print(f"üîç S√©parateur probable: '{likely_sep}' ({separator_counts[likely_sep]} occurrences)")
        
        columns = lines[0].split(likely_sep)
        print(f"üìä Colonnes d√©tect√©es ({len(columns)}): {columns[:5]}...")


# D√©commentez cette ligne pour diagnostiquer votre fichier
# diagnose_csv("2023_T4_sites_Metropole.csv")


if __name__ == "__main__":
    main()


# EXEMPLE DE MATRICE DE PARTAGE R√âSULTANTE:
"""
üìã MATRICE DE PARTAGE ENTRE OP√âRATEURS:
(Nombre de stations communes par paire d'op√©rateurs)

           Orange  SFR  Free  Bouygues
Orange         0   45    23        18
SFR           45    0    31        22  
Free          23   31     0        15
Bouygues      18   22    15         0

üéØ STATISTIQUES DE PARTAGE:
üèÜ Paire avec le plus de partage (45 stations):
   ‚Ä¢ Orange ‚Üî SFR: 45 stations communes

üìä Total de partages par op√©rateur:
   ‚Ä¢ Orange: 86 partages
   ‚Ä¢ SFR: 98 partages  
   ‚Ä¢ Free: 69 partages
   ‚Ä¢ Bouygues: 55 partages

üìä TOP 10 DES PAIRES D'OP√âRATEURS:
 1. Orange + SFR: 45 stations communes
    üìç Paris 15e (Paris)
    üìç Lyon 3e (Rh√¥ne)
    üìç Marseille 8e (Bouches-du-Rh√¥ne)
    ... et 42 autres stations

 2. Free + SFR: 31 stations communes
    üìç Toulouse 1er (Haute-Garonne)
    üìç Nice (Alpes-Maritimes)
    ... et 29 autres stations
"""