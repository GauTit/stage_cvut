import osmnx as ox
import geopandas as gpd
from shapely.geometry import Point, box, LineString
from shapely.ops import nearest_points
import pandas as pd
import numpy as np
import folium
from matplotlib import colormaps
import matplotlib.colors as mcolors
import openpyxl
import math

# Configuration OSMnx
ox.settings.use_cache = True
ox.settings.log_console = True

# Charger les donn√©es de stations
stations_df = pd.read_csv(
    "stations_normandie_orange.csv",
    sep=None,
    engine='python',
    decimal=','
)
# D√©tecter le nom de la station
name_col = next(
    (col for col in stations_df.columns if col.lower() not in ['latitude', 'longitude', 'lat', 'lon', 'lng']),
    stations_df.columns[0]
)

# Cr√©er GeoDataFrame des stations
stations_gdf = gpd.GeoDataFrame(
    stations_df,
    geometry=stations_df.apply(lambda r: Point(r.longitude, r.latitude), axis=1),
    crs="EPSG:4326"
)

# Projection en Lambert-93 (m√®tres)
stations_proj = stations_gdf.to_crs("EPSG:2154")

# D√©finir zone d'int√©r√™t (buffer 10 km)
minx, miny, maxx, maxy = stations_proj.total_bounds
buffer = 10000  # m√®tres
roi = box(minx - buffer, miny - buffer, maxx + buffer, maxy + buffer)

# 1. T√©l√©charger le r√©seau routier (motorway √† primary_link)
road_filter = '["highway"~"motorway|motorway_link|trunk|trunk_link|primary|primary_link"]'
G_road = ox.graph_from_place(
    "Normandie, France",
    network_type=None,
    custom_filter=road_filter,
    retain_all=True
)
nodes_road, edges_road = ox.graph_to_gdfs(G_road)
edges_road = edges_road.to_crs("EPSG:2154")
edges_road = edges_road[edges_road.intersects(roi)].copy()

# 2. T√©l√©charger les voies ferr√©es principales
rail_filter = '["railway"="rail"]'
G_rail = ox.graph_from_place(
    "Normandie, France",
    network_type=None,
    custom_filter=rail_filter,
    retain_all=True
)
nodes_rail, edges_rail = ox.graph_to_gdfs(G_rail)
edges_rail = edges_rail.to_crs("EPSG:2154")
edges_rail = edges_rail[edges_rail.intersects(roi)].copy()

# Sous-ensembles des g√©om√©tries OSM avec attributs utiles
def subset_osm(edges):
    cols = ['geometry', 'osmid']
    for extra in ['ref', 'name']:
        if extra in edges.columns:
            cols.append(extra)
    return edges[cols].copy()

edges_comb = pd.concat([subset_osm(edges_road), subset_osm(edges_rail)], ignore_index=True)

# Option 2: Une station peut √™tre rattach√©e √† plusieurs routes proches
# Cr√©er un buffer autour des stations pour trouver TOUTES les routes proches
stations_buffered = stations_proj.copy()
stations_buffered['geometry'] = stations_buffered.geometry.buffer(1000)  # Buffer de 1km

# Spatial join pour TOUTES les routes dans le buffer
stations_all_routes = gpd.sjoin(
    stations_buffered,
    edges_comb,
    how='left',
    predicate='intersects'
)

# Calculer les distances r√©elles (pas sur le buffer)
stations_all_routes['dist_to_highway_m'] = stations_all_routes.apply(
    lambda row: stations_proj.loc[row.name, 'geometry'].distance(
        edges_comb.loc[row.index_right, 'geometry']
    ) if pd.notna(row.get('index_right')) else np.nan,
    axis=1
)

# Filtrer les relations √† moins de 1 km
stations_all_routes = stations_all_routes[stations_all_routes['dist_to_highway_m'] < 1000]

# Remettre la g√©om√©trie originale des stations (pas le buffer)
stations_all_routes['geometry'] = stations_all_routes.apply(
    lambda row: stations_proj.loc[row.name, 'geometry'], axis=1
)

# V√©rifier si on a des stations valides
if stations_all_routes.empty:
    print("ATTENTION: Aucune station trouv√©e √† moins de 1 km d'une route principale!")
    print("Vous devriez v√©rifier:")
    print("1. Le fichier CSV des stations")
    print("2. Les coordonn√©es des stations")
    print("3. Peut-√™tre augmenter la distance de recherche")
    exit()

# Renommer et nettoyer
stations_all_routes = stations_all_routes.rename(columns={'osmid': 'nearest_osmid'}).drop(columns=['index_right'])

print(f"Nombre de relations station-route trouv√©es : {len(stations_all_routes)}")
print(f"Nombre de stations uniques : {len(stations_all_routes.index.unique())}")

# Fonction pour compter les routes uniques en g√©rant les listes
def count_unique_osmids(series):
    """Compte les osmids uniques en g√©rant les listes"""
    unique_osmids = set()
    for item in series:
        if isinstance(item, list):
            # Pour les listes, ajouter tous les √©l√©ments non-null
            for subitem in item:
                if subitem is not None and not (isinstance(subitem, float) and math.isnan(subitem)):
                    unique_osmids.add(subitem)
        elif item is not None and not (isinstance(item, float) and math.isnan(item)):
            # Pour les valeurs simples, v√©rifier si ce n'est pas NaN
            unique_osmids.add(item)
    return len(unique_osmids)

print(f"Nombre de routes uniques : {count_unique_osmids(stations_all_routes['nearest_osmid'])}")

# Gestion des osmids multiples (liste -> tuple)
def create_osmid_key(osmid):
    if isinstance(osmid, list):
        return tuple(sorted(osmid))
    if pd.isna(osmid):
        return None
    return (osmid,)

stations_all_routes['osmid_key'] = stations_all_routes['nearest_osmid'].apply(create_osmid_key)

# Assurer la pr√©sence des colonnes 'ref' et 'name'
for col in ['ref', 'name']:
    if col not in stations_all_routes.columns:
        stations_all_routes[col] = np.nan

# Cr√©ation de la cl√© parent (ref > name > osmid)
def create_parent_key(row):
    ref = row['ref']
    if not (isinstance(ref, float) and math.isnan(ref)):
        if isinstance(ref, list) and ref:
            return f"ref:{';'.join(map(str, ref))}"
        if isinstance(ref, str) and ref.strip():
            return f"ref:{ref.strip()}"
        if not isinstance(ref, (list, str)):
            return f"ref:{ref}"
    name = row['name']
    if isinstance(name, str) and name.strip():
        return f"name:{name.strip()}"
    return create_osmid_key(row['nearest_osmid'])

stations_all_routes['parent_key'] = stations_all_routes.apply(create_parent_key, axis=1)

# Utiliser stations_all_routes pour le reste du traitement
stations_proj = stations_all_routes.copy()

# Statistiques par route et export Excel
route_stats = (
    stations_proj.groupby('parent_key')
    .size()
    .reset_index(name='station_count')
    .sort_values('station_count', ascending=False)
)

# V√©rification et affichage des statistiques
if not route_stats.empty:
    top = route_stats.iloc[0]
    print(f"Route avec le plus de stations : {top['parent_key']} ({top['station_count']} stations)")
    print(f"Nombre total de routes trouv√©es : {len(route_stats)}")
    print(f"Nombre total de stations li√©es : {stations_proj.shape[0]}")
else:
    print("Aucune route trouv√©e avec des stations associ√©es")

stations_export = stations_proj.copy()
# Correction: utiliser les coordonn√©es de la g√©om√©trie correctement
stations_export['latitude'] = stations_export.geometry.to_crs("EPSG:4326").y
stations_export['longitude'] = stations_export.geometry.to_crs("EPSG:4326").x
stations_export = stations_export.drop(columns=['geometry'])

output_excel = "stations_et_routes_summary.xlsx"
with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
    stations_export[
        ['latitude','longitude','nearest_osmid','ref','name','dist_to_highway_m','parent_key']
    ].to_excel(writer, sheet_name='Stations', index=False)
    route_stats.to_excel(writer, sheet_name='Route_Stats', index=False)

print(f"Fichier Excel g√©n√©r√© : {output_excel}")

# Calcul des liens entre voisins sur la m√™me route avec TSP OUVERT et limite de distance
# Filtrer uniquement les stations valides (< 1km d'une route)
valid = stations_proj.dropna(subset=['dist_to_highway_m'])
valid = valid[valid['dist_to_highway_m'] < 1000]
neighbor_geoms = []

# CONSTANTE: Distance maximale entre stations voisines (en m√®tres)
MAX_NEIGHBOR_DISTANCE = 20000  # 20 km

def solve_tsp_open_with_distance_limit(points, max_distance):
    """
    R√©soudre TSP OUVERT avec algorithme glouton et limite de distance
    - Pas de retour au d√©part
    - √âvite les liens > max_distance
    """
    if len(points) <= 2:
        return list(range(len(points)))
    
    # Matrice des distances
    n = len(points)
    distances = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            if i != j:
                distances[i][j] = points[i]['geometry'].distance(points[j]['geometry'])
    
    # Algorithme du plus proche voisin AVEC limite de distance
    unvisited = set(range(1, n))
    current = 0
    tour = [current]
    
    while unvisited:
        # Trouver le plus proche voisin dans la limite de distance
        valid_neighbors = [x for x in unvisited if distances[current][x] <= max_distance]
        
        if not valid_neighbors:
            # Si aucun voisin dans la limite, arr√™ter ce segment
            break
            
        nearest = min(valid_neighbors, key=lambda x: distances[current][x])
        tour.append(nearest)
        unvisited.remove(nearest)
        current = nearest
    
    return tour

def create_neighbor_links_with_limit(points, max_distance):
    """
    Cr√©er des liens entre stations voisines avec limite de distance
    Peut cr√©er plusieurs segments s√©par√©s si n√©cessaire
    """
    if len(points) < 2:
        return []
    
    links = []
    
    # Pour 2 stations seulement
    if len(points) == 2:
        dist = points[0]['geometry'].distance(points[1]['geometry'])
        if dist <= max_distance:
            links.append(LineString([points[0]['coords'], points[1]['coords']]))
        else:
            print(f"‚ö†Ô∏è  Stations trop √©loign√©es ({dist/1000:.1f} km > {max_distance/1000} km) - lien ignor√©")
        return links
    
    # Pour plus de 2 stations, utiliser TSP avec limite
    unprocessed = list(range(len(points)))
    
    while unprocessed:
        # Commencer un nouveau segment depuis la premi√®re station non trait√©e
        start_idx = unprocessed[0]
        current_points = [points[i] for i in unprocessed]
        
        # Mapper les indices locaux vers les indices globaux
        local_to_global = {i: unprocessed[i] for i in range(len(current_points))}
        
        # R√©soudre TSP pour ce sous-ensemble
        tour = solve_tsp_open_with_distance_limit(current_points, max_distance)
        
        # Cr√©er les liens pour ce segment
        for i in range(len(tour) - 1):
            idx1 = local_to_global[tour[i]]
            idx2 = local_to_global[tour[i + 1]]
            
            dist = points[idx1]['geometry'].distance(points[idx2]['geometry'])
            if dist <= max_distance:
                links.append(LineString([points[idx1]['coords'], points[idx2]['coords']]))
            else:
                print(f"‚ö†Ô∏è  Lien ignor√©: distance {dist/1000:.1f} km > limite {max_distance/1000} km")
        
        # Retirer les stations trait√©es
        processed_global_indices = [local_to_global[i] for i in tour]
        for idx in processed_global_indices:
            unprocessed.remove(idx)
        
        # Si il reste des stations non connect√©es, recommencer
        if len(unprocessed) == len(current_points):
            # √âviter boucle infinie - prendre au moins la premi√®re station
            unprocessed.pop(0)
    
    return links

# V√©rifier s'il y a des stations valides avant de continuer
if valid.empty:
    neighbors_wgs = gpd.GeoDataFrame(columns=['geometry'], crs="EPSG:4326")
else:
    total_links_created = 0
    total_links_skipped = 0
    
    for pk, group in valid.groupby('parent_key'):
        if len(group) < 2:
            continue
        
        # Cr√©er une liste des stations uniques pour cette route
        stations_dict = {}
        for idx, row in group.iterrows():
            station_id = (row.geometry.x, row.geometry.y)  # Utiliser les coordonn√©es comme cl√© unique
            if station_id not in stations_dict:
                stations_dict[station_id] = {
                    'idx': idx,
                    'geometry': row.geometry,
                    'coords': (row.geometry.x, row.geometry.y)
                }
        
        stations_list = list(stations_dict.values())
        
        
        # Cr√©er les liens avec limite de distance
        route_links = create_neighbor_links_with_limit(stations_list, MAX_NEIGHBOR_DISTANCE)
        
        links_created = len(route_links)
        total_links_created += links_created
        
        neighbor_geoms.extend(route_links)
        

    
    # Cr√©er le GeoDataFrame des voisins seulement si on a des g√©om√©tries
    if neighbor_geoms:
        neighbors_proj = gpd.GeoDataFrame(geometry=neighbor_geoms, crs="EPSG:2154")
        neighbors_wgs = neighbors_proj.to_crs("EPSG:4326")
        print(f"\nüìä Total: {total_links_created} liens cr√©√©s entre stations voisines (limite: {MAX_NEIGHBOR_DISTANCE/1000} km)")
    else:
        neighbors_wgs = gpd.GeoDataFrame(columns=['geometry'], crs="EPSG:4326")
        print(f"‚ö†Ô∏è  Aucun lien cr√©√© - toutes les stations sont trop √©loign√©es (> {MAX_NEIGHBOR_DISTANCE/1000} km)")








# Distances
print(f"‚úÖ Distance moyenne station ‚Üí route (m) : {stations_proj['dist_to_highway_m'].mean():.1f}")
print(f"‚úÖ Distance m√©diane station ‚Üí route (m) : {stations_proj['dist_to_highway_m'].median():.1f}")

# Compter combien de stations DISTINCTES (index unique) ont √©t√© rattach√©es
total_stations_input = 1456
nb_stations_rattachees_uniques = stations_proj.index.nunique()
nb_non_rattachees = total_stations_input - nb_stations_rattachees_uniques

print(f"\nüìå Nombre de stations dans le CSV : {total_stations_input}")
print(f"üìå Nombre de stations rattach√©es √† une route : {nb_stations_rattachees_uniques}")
print(f"üìå Pourcentage de stations rattach√©es : {nb_stations_rattachees_uniques / total_stations_input * 100:.2f}%")
print(f"üìå Nombre de stations non rattach√©es : {nb_non_rattachees}")

